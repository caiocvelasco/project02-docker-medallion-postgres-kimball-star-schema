{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an ETL Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Data Transformation\n",
    "import requests     # Establishing connection with the web (API)\n",
    "import json         # Exposes an API familiar to users of the standard library marshal and pickle modules\n",
    "import pytest       # Makes it easy to write small, readable tests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sqlalchemy\n",
    "from sqlalchemy.engine import Engine, create_engine\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [E] Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API\n",
    "- Data Source: https://docs.coincap.io/#89deffa0-ab03-4e0a-8d92-637a857d2c91\n",
    "- Data comes in a JSON format (semi-structured data) from a 3rd Party"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(api_get_request_url):\n",
    "    \"\"\"\n",
    "    Create and return a raw JSON extracted from an external API via GET Request.\n",
    "\n",
    "    Args:\n",
    "        api_get_request_url: The URL for API's GET Request.\n",
    "\n",
    "    Returns:\n",
    "        raw_data_json: a raw JSON with the API data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # GET Request. Package the request, send the request and catch the response r\n",
    "    r = requests.get(api_get_request_url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if r.status_code == 200:\n",
    "        # Extract JSON data from response: Decode the JSON data into a dictionary\n",
    "        raw_data_json = r.json()\n",
    "    else:\n",
    "        print(f\"Error. Non-success status code: {r.status_code}\")\n",
    "    \n",
    "    # Return the json\n",
    "    return raw_data_json\n",
    "\n",
    "# Call the extract() function\n",
    "raw_data_json = extract(\"https://api.coincap.io/v2/assets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing JSON names (keys):\n",
      "-> data\n",
      "-> timestamp\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb87ade380144448581150f349a7ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='{\\n  \"data\": [\\n    {\\n      \"id\": \"bitcoin\",\\n      \"rank\": \"1\",\\n      \"symbol\": \"BTC\",\\n   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick visualization\n",
    "print(\"Printing JSON names (keys):\")\n",
    "for key in raw_data_json.keys():\n",
    "    print(\"->\", key)\n",
    "\n",
    "# Convert JSON to string\n",
    "json_str = json.dumps(raw_data_json, indent=2)\n",
    "\n",
    "# Create a text area widget\n",
    "json_output = widgets.Textarea(\n",
    "    value=json_str,\n",
    "    placeholder='JSON data',\n",
    "    description='JSON:',\n",
    "    disabled=True,\n",
    "    layout=widgets.Layout(width='80%', height='200px')\n",
    ")\n",
    "\n",
    "# Display the widget\n",
    "display(json_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [T] Transformation\n",
    "* Exploring JSON Structure\n",
    "* Data Normalization\n",
    "    * Transforming the JSON into a table (as a Dataframe)\n",
    "* Data Exploration & Cleaning\n",
    "    * Check for: Missing Data, Data Types, Rounding needs.\n",
    "* Transforming into a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring JSON Structure\n",
    "* Exploring the JSON name-value pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Json's type from the API request: <class 'dict'>\n",
      "It's a dict, so let's check how many keys it has: 2\n",
      "It is a nested JSON, with two key-value pais: data and timestamp.\n",
      "The actual information comes in the 'data' key along with its associated 'timestamp' as another key.\n",
      "How many key-value pairs in the 'data' key: 100\n",
      "-> There are 12 features in a single record of 'data'.\n",
      "-> In total, there are 100 records stored in 'data' and each record has 12 features.\n",
      "We should see the same when storing in Dataframe.\n"
     ]
    }
   ],
   "source": [
    "# Exploring the JSON structure\n",
    "print(\"This is the Json's type from the API request:\", type(raw_data_json))\n",
    "print(\"It's a dict, so let's check how many keys it has:\", len(raw_data_json))\n",
    "\n",
    "# Saving Keys and Values as Lists\n",
    "raw_data_json_keys_ls = list(raw_data_json.keys())\n",
    "raw_data_json_values_ls = list(raw_data_json.values())\n",
    "\n",
    "print(\"It is a nested JSON, with two key-value pais: data and timestamp.\")\n",
    "print(\"The actual information comes in the 'data' key along with its associated 'timestamp' as another key.\")\n",
    "print(\"How many key-value pairs in the 'data' key:\", len(raw_data_json_values_ls[0]))\n",
    "potential_columns = len(raw_data_json_values_ls[0][0])\n",
    "potential_rows = len(raw_data_json_values_ls[0])\n",
    "print(f\"-> There are {potential_columns} features in a single record of 'data'.\")\n",
    "print(f\"-> In total, there are {potential_rows} records stored in 'data' and each record has {potential_columns} features.\")\n",
    "print(\"We should see the same when storing in Dataframe.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation Function\n",
    "Notes: \n",
    "* The list of records are stored in the 'data' key of the JSON file, as seen above.\n",
    "* Before creating the transformation function, we performed a data exploration:\n",
    "    * There were some columns that are supposed to be **Numerical** data, but are stored as **Categorical** (`object`) data. We converted them.\n",
    "    * There were some **Missing** (`NULL`) data ('maxSupply', 'explorer'). We handled it by hardcoding within the transformation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the Converting part\n",
    "# Selecting the columns and their correct types\n",
    "cols_datatypes = {\n",
    "    'rank' : int,\n",
    "    'supply' : float,\n",
    "    'maxSupply' : float,\n",
    "    'marketCapUsd' : float,\n",
    "    'volumeUsd24Hr' : float,\n",
    "    'priceUsd' : float,\n",
    "    'changePercent24Hr' : float,\n",
    "    'vwap24Hr' : float\n",
    "}\n",
    "\n",
    "# For the Rounding part\n",
    "# Selecting the columns we want to round to some decimal places\n",
    "cols_to_round = ['supply', 'maxSupply', 'marketCapUsd', 'priceUsd', 'changePercent24Hr', 'vwap24Hr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(raw_data_json, cols_datatypes, cols_to_round):\n",
    "    \"\"\"\n",
    "    Create and return a raw dataset in the DataFrame format based on a JSON.\n",
    "    Here, the function is not automated to both the missing values and the rounding parts.\n",
    "    You need to hardcode it here how to handle each case.\n",
    "\n",
    "    Args:\n",
    "        raw_data_json: The raw json returned by the extraction function.\n",
    "        cols_datatypes: A dictionary of columns and the associated types you want for them.\n",
    "    Returns:\n",
    "        raw_normalized_data_df: a raw, normalized dataset in the DataFrame format.\n",
    "    \"\"\"    \n",
    "    \n",
    "    # 1) Data Normalization\n",
    "    # record_path = \"data\": path to list of records.\n",
    "    # sep = \".\": Nested records will generate names separated by 'sep'.\n",
    "    raw_normalized_data_df = pd.json_normalize(raw_data_json, record_path = \"data\", sep = '.') \n",
    "\n",
    "    # Assert that the transform function returns a pd.DataFrame\n",
    "    assert isinstance(raw_normalized_data_df, pd.DataFrame)\n",
    "    \n",
    "    # 2) Data Cleaning\n",
    "    # Inner Function to Convert Categorical to Numerical\n",
    "    def convert_cols_cat_to_num(df, cols_datatypes):\n",
    "        \"\"\"\n",
    "        Gets a dataframe with specific categorical columns and convert them into numerical columns. \n",
    "\n",
    "        Args:\n",
    "            df: The dataframe with the columns you want to convert.\n",
    "            cols_datatypes: A dictionary of columns and the associated types you want for them. \n",
    "\n",
    "        Returns:\n",
    "            Engine: A dataframe with columns converted to the types you want. \n",
    "        \"\"\"\n",
    "        for col, datatype in cols_datatypes.items():\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(datatype)\n",
    "        return df\n",
    "    \n",
    "    # Converting Categorical to Numerical\n",
    "    converted_data_df = convert_cols_cat_to_num(raw_normalized_data_df, cols_datatypes)\n",
    "    # Save a copy\n",
    "    cleaned_data_df = converted_data_df.copy()\n",
    "    \n",
    "    # Handling Missing Values\n",
    "    cleaned_data_df[\"maxSupply\"] = cleaned_data_df[\"maxSupply\"].fillna(0)\n",
    "    cleaned_data_df[\"explorer\"] = cleaned_data_df[\"explorer\"].fillna('not available')    \n",
    "\n",
    "    # Inner function to round columns\n",
    "    # def round_to_two_decimal_places(number):\n",
    "    #     return round(number, 2)\n",
    "\n",
    "    # Rounding columns\n",
    "    # Note: 'applymap' applies a function that accepts and returns a scalar to every element of a DataFrame\n",
    "    cleaned_data_df[cols_to_round] = cleaned_data_df[cols_to_round].apply(lambda x: x.round(2))\n",
    "\n",
    "    return cleaned_data_df\n",
    "\n",
    "# Try-except block for the transform function\n",
    "try:\n",
    "    # Transform the raw_data_json into a cleaned and tabular dataframe\n",
    "    cleaned_data_df = transform(raw_data_json, cols_datatypes, cols_to_round)\n",
    "except:\n",
    "    print(\"There is an error with the transform function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 100 non-null    object \n",
      " 1   rank               100 non-null    int64  \n",
      " 2   symbol             100 non-null    object \n",
      " 3   name               100 non-null    object \n",
      " 4   supply             100 non-null    float64\n",
      " 5   maxSupply          100 non-null    float64\n",
      " 6   marketCapUsd       100 non-null    float64\n",
      " 7   volumeUsd24Hr      100 non-null    float64\n",
      " 8   priceUsd           100 non-null    float64\n",
      " 9   changePercent24Hr  100 non-null    float64\n",
      " 10  vwap24Hr           100 non-null    float64\n",
      " 11  explorer           100 non-null    object \n",
      "dtypes: float64(7), int64(1), object(4)\n",
      "memory usage: 9.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking the cleaned dataset\n",
    "cleaned_data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>symbol</th>\n",
       "      <th>name</th>\n",
       "      <th>supply</th>\n",
       "      <th>maxSupply</th>\n",
       "      <th>marketCapUsd</th>\n",
       "      <th>volumeUsd24Hr</th>\n",
       "      <th>priceUsd</th>\n",
       "      <th>changePercent24Hr</th>\n",
       "      <th>vwap24Hr</th>\n",
       "      <th>explorer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bitcoin</td>\n",
       "      <td>1</td>\n",
       "      <td>BTC</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>1.971039e+07</td>\n",
       "      <td>21000000.0</td>\n",
       "      <td>1.367663e+12</td>\n",
       "      <td>3.961673e+09</td>\n",
       "      <td>69387.91</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>69670.50</td>\n",
       "      <td>https://blockchain.info/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ethereum</td>\n",
       "      <td>2</td>\n",
       "      <td>ETH</td>\n",
       "      <td>Ethereum</td>\n",
       "      <td>1.201542e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.407018e+11</td>\n",
       "      <td>2.951669e+09</td>\n",
       "      <td>3667.80</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>3691.50</td>\n",
       "      <td>https://etherscan.io/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tether</td>\n",
       "      <td>3</td>\n",
       "      <td>USDT</td>\n",
       "      <td>Tether</td>\n",
       "      <td>1.124810e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.125185e+11</td>\n",
       "      <td>8.539388e+09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>https://www.omniexplorer.info/asset/31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>binance-coin</td>\n",
       "      <td>4</td>\n",
       "      <td>BNB</td>\n",
       "      <td>BNB</td>\n",
       "      <td>1.668011e+08</td>\n",
       "      <td>166801148.0</td>\n",
       "      <td>1.074916e+11</td>\n",
       "      <td>5.299415e+08</td>\n",
       "      <td>644.43</td>\n",
       "      <td>-5.45</td>\n",
       "      <td>656.49</td>\n",
       "      <td>https://etherscan.io/token/0xB8c77482e45F1F44d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>solana</td>\n",
       "      <td>5</td>\n",
       "      <td>SOL</td>\n",
       "      <td>Solana</td>\n",
       "      <td>4.607843e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.305181e+10</td>\n",
       "      <td>3.265345e+08</td>\n",
       "      <td>158.54</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>160.41</td>\n",
       "      <td>https://explorer.solana.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  rank symbol      name        supply    maxSupply  \\\n",
       "0       bitcoin     1    BTC   Bitcoin  1.971039e+07   21000000.0   \n",
       "1      ethereum     2    ETH  Ethereum  1.201542e+08          0.0   \n",
       "2        tether     3   USDT    Tether  1.124810e+11          0.0   \n",
       "3  binance-coin     4    BNB       BNB  1.668011e+08  166801148.0   \n",
       "4        solana     5    SOL    Solana  4.607843e+08          0.0   \n",
       "\n",
       "   marketCapUsd  volumeUsd24Hr  priceUsd  changePercent24Hr  vwap24Hr  \\\n",
       "0  1.367663e+12   3.961673e+09  69387.91              -0.33  69670.50   \n",
       "1  4.407018e+11   2.951669e+09   3667.80              -0.79   3691.50   \n",
       "2  1.125185e+11   8.539388e+09      1.00              -0.10      1.00   \n",
       "3  1.074916e+11   5.299415e+08    644.43              -5.45    656.49   \n",
       "4  7.305181e+10   3.265345e+08    158.54              -1.69    160.41   \n",
       "\n",
       "                                            explorer  \n",
       "0                           https://blockchain.info/  \n",
       "1                              https://etherscan.io/  \n",
       "2             https://www.omniexplorer.info/asset/31  \n",
       "3  https://etherscan.io/token/0xB8c77482e45F1F44d...  \n",
       "4                       https://explorer.solana.com/  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first records\n",
    "cleaned_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transforming into a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transform a Python Dataframe into a CSV file \n",
    "\n",
    "def df_to_csv(df, file_name):\n",
    "    \"\"\"\n",
    "    Transforms a pandas DataFrame into a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to be transformed.\n",
    "    file_name (str): The name of the CSV file to be created.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df.to_csv(file_name, index=False)\n",
    "        print(f\"DataFrame successfully saved to {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving the DataFrame to CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully saved to /workspace/sources/crypto_mkt.csv\n"
     ]
    }
   ],
   "source": [
    "# Calling the function for the Crypto dataset\n",
    "df_to_csv(cleaned_data_df, '/workspace/sources/crypto_mkt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [L] Load\n",
    "* Loading data to Postgres.\n",
    "    * Open a SQL connection with SQLAlchemy\n",
    "    * .to_sql()\n",
    "* Data Quality checks:\n",
    "    * Validate that data was correctly persisted in postgres\n",
    "        * Ensure it can be queried\n",
    "            * pd.read_sql()\n",
    "        * Make sure counts match\n",
    "        * Validate each row is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Function that created the SQL Engine based on SQLAlchemy\n",
    "def create_db_engine(connection_uri: str) -> Engine: # Arrow indicates that the function returns an object of type Engine\n",
    "    \"\"\"\n",
    "    Create and return a SQLAlchemy engine based on the provided connection URI.\n",
    "\n",
    "    Args:\n",
    "        connection_uri (str): The connection URI for the database.\n",
    "\n",
    "    Returns:\n",
    "        Engine: A SQLAlchemy engine connected to the specified database.\n",
    "    \"\"\"\n",
    "    db_engine = create_engine(connection_uri)\n",
    "    return db_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve individual components from environment variables\n",
    "user = os.getenv('POSTGRES_USER')\n",
    "password = os.getenv('POSTGRES_PASSWORD')\n",
    "host = os.getenv('POSTGRES_HOST')\n",
    "db_name = os.getenv('POSTGRES_DB')\n",
    "\n",
    "# Ensure the connection URI is retrieved successfully\n",
    "if not all([user, password, host, db_name]):\n",
    "    raise ValueError(\"One or more environment variables for the database connection are not set\")\n",
    "\n",
    "# Construct the connection URI\n",
    "connection_uri = f\"postgresql://{user}:{password}@{host}/{db_name}\"\n",
    "\n",
    "# Ensure the connection URI is retrieved successfully\n",
    "if connection_uri is None:\n",
    "    raise ValueError(\"DATABASE_URL environment variable is not set\")\n",
    "\n",
    "# Create the database engine\n",
    "db_engine = create_db_engine(connection_uri)\n",
    "\n",
    "# Close the engine connection\n",
    "db_engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load/Persist data in Postgres\n",
    "def load(cleaned_data_df, con_engine):\n",
    "    \"\"\"\n",
    "    Load/persist data in PostgreSQL database.\n",
    "\n",
    "    Args:\n",
    "        raw_normalized_data_df (DataFrame): The DataFrame containing the data to be loaded.\n",
    "        con_engine (Engine): SQLAlchemy engine for database connection.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # to_sql: Write records stored in a DataFrame to a SQL database.\n",
    "    cleaned_data_df.to_sql(name=\"crypto_mkt\", con=con_engine, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "* In the Load function, we are basically checking if a table named 'crypto_mkt' exists. If it exists, the `'if_exists' = 'replace'`  argument will drop the table before inserting new values.\n",
    "* If you want something different, please check the [to_sql()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_sql.html) documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id  rank symbol      name        supply    maxSupply  \\\n",
      "0       bitcoin     1    BTC   Bitcoin  1.971039e+07   21000000.0   \n",
      "1      ethereum     2    ETH  Ethereum  1.201542e+08          0.0   \n",
      "2        tether     3   USDT    Tether  1.124810e+11          0.0   \n",
      "3  binance-coin     4    BNB       BNB  1.668011e+08  166801148.0   \n",
      "4        solana     5    SOL    Solana  4.607843e+08          0.0   \n",
      "\n",
      "   marketCapUsd  volumeUsd24Hr  priceUsd  changePercent24Hr  vwap24Hr  \\\n",
      "0  1.367663e+12   3.961673e+09  69387.91              -0.33  69670.50   \n",
      "1  4.407018e+11   2.951669e+09   3667.80              -0.79   3691.50   \n",
      "2  1.125185e+11   8.539388e+09      1.00              -0.10      1.00   \n",
      "3  1.074916e+11   5.299415e+08    644.43              -5.45    656.49   \n",
      "4  7.305181e+10   3.265345e+08    158.54              -1.69    160.41   \n",
      "\n",
      "                                            explorer  \n",
      "0                           https://blockchain.info/  \n",
      "1                              https://etherscan.io/  \n",
      "2             https://www.omniexplorer.info/asset/31  \n",
      "3  https://etherscan.io/token/0xB8c77482e45F1F44d...  \n",
      "4                       https://explorer.solana.com/  \n"
     ]
    }
   ],
   "source": [
    "# Call the load function to load the transformed data to persistent storage\n",
    "load(cleaned_data_df, db_engine)\n",
    "\n",
    "# Query the data in the crypto_mkt table, check the head of the DataFrame\n",
    "to_validate = pd.read_sql(\"SELECT * FROM crypto_mkt\", con=db_engine)\n",
    "print(to_validate.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
